{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC Key pressed\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "if cap.isOpened():\n",
    "    delay = int(1000 / cap.get(cv2.CAP_PROP_FPS))\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imshow(\"Movie\", img_gray)\n",
    "            if cv2.waitKey(delay) & 0xFF == 27 :\n",
    "                print(\"ESC Key pressed\")\n",
    "                break \n",
    "        else:\n",
    "            print(ret, img)\n",
    "            break\n",
    "else:\n",
    "    print(\"File not opened\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 하르 특징분류기로 얼굴, 눈, 입 인식하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T04:34:36.355649Z",
     "start_time": "2021-06-10T04:28:36.963533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading haar cascades...\n",
      "[INFO] starting video stream...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# initialize a dictionary that maps the name of the haar cascades to\n",
    "# their filenames\n",
    "detectorPaths = {\n",
    "\t\"face\": \"haarcascade_frontalface_default.xml\",\n",
    "\t\"eyes\": \"haarcascade_eye.xml\",\n",
    "\t\"smile\": \"haarcascade_smile.xml\",\n",
    "}\n",
    "# initialize a dictionary to store our haar cascade detectors\n",
    "print(\"[INFO] loading haar cascades...\")\n",
    "detectors = {}\n",
    "# loop over our detector paths\n",
    "for (name, path) in detectorPaths.items():\n",
    "\tdetectors[name] = cv2.CascadeClassifier(path)\n",
    "    \n",
    "# initialize the video stream and allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if cap.isOpened():\n",
    "    delay = int(1000 / cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    while True:\n",
    "        # grab the frame from the video stream, resize it, and convert it\n",
    "        # to grayscale\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # perform face detection using the appropriate haar cascade\n",
    "            faceRects = detectors[\"face\"].detectMultiScale(\n",
    "                gray, scaleFactor=1.05, minNeighbors=5, minSize=(30, 30),\n",
    "                flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "            # loop over the face bounding boxes\n",
    "            for (fX, fY, fW, fH) in faceRects:\n",
    "                # extract the face ROI\n",
    "                faceROI = gray[fY:fY+ fH, fX:fX + fW]\n",
    "                # apply eyes detection to the face ROI\n",
    "                eyeRects = detectors[\"eyes\"].detectMultiScale(\n",
    "                    faceROI, scaleFactor=1.1, minNeighbors=10,\n",
    "                    minSize=(15, 15), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "                # apply smile detection to the face ROI\n",
    "                smileRects = detectors[\"smile\"].detectMultiScale(\n",
    "                    faceROI, scaleFactor=1.1, minNeighbors=10,\n",
    "                    minSize=(15, 15), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "                # loop over the eye bounding boxes\n",
    "                for (eX, eY, eW, eH) in eyeRects:\n",
    "                    # draw the eye bounding box\n",
    "                    ptA = (fX + eX, fY + eY)\n",
    "                    ptB = (fX + eX + eW, fY + eY + eH)\n",
    "                    cv2.rectangle(frame, ptA, ptB, (0, 0, 255), 2)\n",
    "                # loop over the smile bounding boxes\n",
    "                for (sX, sY, sW, sH) in smileRects:\n",
    "                    # draw the smile bounding box\n",
    "                    ptA = (fX + sX, fY + sY)\n",
    "                    ptB = (fX + sX + sW, fY + sY + sH)\n",
    "                    cv2.rectangle(frame, ptA, ptB, (255, 0, 0), 2)\n",
    "                # draw the face bounding box on the frame\n",
    "                cv2.rectangle(frame, (fX, fY), (fX + fW, fY + fH),\n",
    "                    (0, 255, 0), 2)\n",
    "            # show the output frame\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(delay) & 0xFF\n",
    "            # if the `q` key was pressed, break from the loop\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            print(ret, frame)\n",
    "            break\n",
    "else:\n",
    "    print(\"File not opened\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not opened\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
